positive_label: ['21'], model: head, augmentation_time: 2
model:head, size_list: [3]
studytype_users_dates_range: ['study1_5_0117_1-10', 'study1_6_0117_1-10', 'study1_7_0117_1-10', 'study1_8_0117_1-10', 'study1_9_0118_1-10', 'study1_10_0118_1-10', 'study1_11_0118_1-7', 'study1_12_0118_1-10', 'study1_14_0118_1-10', 'study1_15_0118_1-10', 'study1_17_0119_1-10', 'study1_18_0119_1-10', 'study1_19_0119_1-10', 'study1_20_0119_1-10', 'study1_21_0119_1-10', 'study1_22_0119_1-10', 'study1_23_0119_1-10']
----------------pin_list: [1]----------------
result_array.shape: (334, 980)
positive_features_to_augment.shape: (334, 980)
result_array_augmented.shape: (668, 980)
labels:['5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5' '5'
 '5' '5' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6' '6'
 '6' '6' '6' '6' '7' '7' '7' '7' '7' '7' '7' '7' '7' '7' '7' '7' '7' '7'
 '7' '7' '7' '7' '7' '7' '8' '8' '8' '8' '8' '8' '8' '8' '8' '8' '8' '8'
 '8' '8' '8' '8' '8' '8' '8' '8' '9' '9' '9' '9' '9' '9' '9' '9' '9' '9'
 '9' '9' '9' '9' '9' '9' '9' '9' '9' '9' '10' '10' '10' '10' '10' '10'
 '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10' '10'
 '11' '11' '11' '11' '11' '11' '11' '11' '11' '11' '11' '11' '11' '11'
 '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12' '12'
 '12' '12' '12' '12' '12' '12' '14' '14' '14' '14' '14' '14' '14' '14'
 '14' '14' '14' '14' '14' '14' '14' '14' '14' '14' '14' '14' '15' '15'
 '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15' '15'
 '15' '15' '15' '15' '17' '17' '17' '17' '17' '17' '17' '17' '17' '17'
 '17' '17' '17' '17' '17' '17' '17' '17' '17' '17' '18' '18' '18' '18'
 '18' '18' '18' '18' '18' '18' '18' '18' '18' '18' '18' '18' '18' '18'
 '18' '18' '19' '19' '19' '19' '19' '19' '19' '19' '19' '19' '19' '19'
 '19' '19' '19' '19' '19' '19' '19' '19' '20' '20' '20' '20' '20' '20'
 '20' '20' '20' '20' '20' '20' '20' '20' '20' '20' '20' '20' '20' '20'
 '21' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21'
 '21' '21' '21' '21' '21' '21' '22' '22' '22' '22' '22' '22' '22' '22'
 '22' '22' '22' '22' '22' '22' '22' '22' '22' '22' '22' '22' '23' '23'
 '23' '23' '23' '23' '23' '23' '23' '23' '23' '23' '23' '23' '23' '23'
 '23' '23' '23' '23']
binary_labels:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0]
binary_labels_augmented:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1]
data_scaled:(334, 980)

data augment for multiclass
-----------svm_multi_kfold------------
Average Accuracy: 0.9969969969969971 
precision: 0.9974259974259975 
recalls: 0.9969969969969971 
f1s: 0.9969969969969971
------------mlp_multi_kfold------------
Average Accuracy: 0.9910446160446161 
precision: 0.9927427427427428 
recalls: 0.9910446160446161 
f1s: 0.9906571922196922

data augment for binary
---------knn_binary_kfold------------
Average Accuracy: 0.9925194252548512 
precision: 0.9889344167419033 
recalls: 0.9971751412429378 
f1s: 0.9929909901043779 
fars: 0.01272893772893773 
frrs: 0.002824858757062147
----------svm_binary_kfold------------
Average Accuracy: 0.9984984984984985 
precision: 0.9971988795518207 
recalls: 1.0 
f1s: 0.9985935302390999 
fars: 0.0032051282051282055 
frrs: 0.0
------------mlp_binary_kfold------------
平均准确性: 0.9985052316890881 
精确度: 0.9971988795518207 
召回率: 1.0 
F1 值: 0.9985935302390999 
FAR: 0.003174603174603175 
FRR: 0.0
member: study1_13_0118_1-10, size: 3, pin: 1, num: 1, augment_time: 1
result_array.shape: (30, 980)
positive_features_to_augment.shape: (30, 980)
result_array_augmented.shape: (60, 980)

latter_data_scaled: (30, 980)

--------knn_binary------------
准确度: 0.9925373134328358
混淆矩阵:
[[71  1]
 [ 0 62]]
精确度: 0.9841269841269841
召回率: 1.0
F1分数: 0.9919999999999999
FAR: 0.0139
FRR: 0.0000
[0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]
随时间推移的准确率 0.7
---------svm_binary------------
准确度: 1.0
混淆矩阵:
[[65  0]
 [ 0 69]]
精确度: 1.0
召回率: 1.0
F1分数: 1.0
FAR: 0.0000
FRR: 0.0000
[0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]
Confidence [-1.68125127  0.43632279  0.49242947  0.49850507  0.37899425  0.34601402
  0.97014187  0.59869264  0.57382305  0.20815167  0.20815167 -1.51665656
 -1.99623459 -1.56813547 -0.18397966 -0.35803526 -1.72484033  0.06296363
 -1.66038734  0.28724777  0.80215722  0.79845846  1.20334093  0.9995148
  1.22215611  0.99989778  0.80826824  1.00002317  1.00028201  1.14245846]
随时间推移的准确率 0.6
---------svm_multi------------
准确度: 1.0
混淆矩阵:
[[4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]
精确度: 1.0
召回率: 1.0
F1分数: 1.0
['19' '21' '21' '21' '21' '21' '21' '21' '21' '19' '19' '12' '14' '19'
 '21' '21' '12' '21' '12' '21' '21' '21' '21' '21' '21' '21' '21' '21'
 '21' '21'] ['2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '13' '13' '13' '13' '13' '13'
 '13' '13' '13' '13' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21']
Confidence [[13.30139686  2.70759411 12.29811784  7.7717596   4.7276188  10.2340452
   1.69929655 16.31121899  0.70535052  5.73987674 15.30219803 14.30598765
  -0.30997801  3.71251575  8.82622772 11.22855091  6.75905588]
 [14.28571819  2.71779873  6.77826499  8.14960009  4.76645177  2.7251593
  15.29086967  9.09457691 -0.31045834 16.30696925 12.2733733  11.29282633
   0.69860754 13.27278064  5.81781831 10.25334484  2.71167376]
 [10.25301507  4.75069666  7.06248961  8.20991623  5.79498372  1.71179219
  14.26286353 11.253367   -0.31018223 16.30380659 13.25490941 15.30206474
   0.71130801 11.23451403  3.72362953 10.25471324  2.72108851]
 [14.2856735   3.72350568  6.89736426  9.26029886  4.75019317  1.70319905
  11.26717562 10.24753782 -0.31223039 16.30735616 15.29209887 13.30087098
   1.70456575 12.26849006  5.74909654  8.19842924  1.70282794]
 [14.27559676  4.77313981  7.07845207  9.24189701  5.80754285  1.7157706
  11.24801786 12.2535382  -0.31121972 16.30198866 13.26117873 15.30332503
   0.70762713 10.22809391  3.72978559  8.20360175  2.71340237]
 [14.28777317  3.73267015  7.18138118  8.22478213  4.73690774  1.7047447
   9.26016747 12.27043873 -0.3119382  16.30154263 15.28838303 13.29983861
   0.70180275 11.25935254  5.79435891 10.24664631  2.70207837]
 [12.27757071  3.73240516  6.83610471 10.24418676  4.75393369  0.70253834
  15.29138585  9.16931215 -0.31222823 16.3106475  14.27075584 13.29752314
   2.71484129 11.24281195  5.76481261  8.21743177  1.70671644]
 [13.28041355  3.75702702  6.83560749  8.08656752  4.7617614   1.70809416
   9.25724339 12.26872532 -0.31205786 16.30581455 15.29100082 14.30055096
   0.7028092  11.24967761  5.77641838 10.25518335  2.70192535]
 [13.29224419  3.74806006 10.15012494  5.74475476  4.71835983  2.71474956
   7.10520378 14.30007495 -0.31091423 16.30449981 15.29671163 12.29560863
   0.69477727  9.14967107  8.07711716 11.28958822  1.69941381]
 [11.28091817  3.76196317 11.25574265  6.81479887  5.74855423  1.72737319
   7.88992582 16.3010103  -0.31175746 15.29301453 13.28085264 14.30504905
   0.69923709  9.01503519  4.74422248 11.27043695  2.70867505]
 [11.28091817  3.76196317 11.25574265  6.81479887  5.74855423  1.72737319
   7.88992582 16.3010103  -0.31175746 15.29301453 13.28085264 14.30504905
   0.69923709  9.01503519  4.74422248 11.27043695  2.70867505]
 [13.28008073  2.70682661 16.31309242 11.23590856  6.78694597  8.90816556
   1.70296337 15.31090357 -0.30544249  5.72415108 12.27475359 14.31113281
   0.69366559  4.71688057  3.71942139 10.22004559  7.77892426]
 [ 7.90597338 10.2206058   3.70333472 16.3109021  12.27594479  0.70819085
  13.26642024  1.696621   -0.30472146  8.21063916  3.71484373 14.30097563
   9.22139722 15.2956043   5.82105604  3.73230004 10.22250171]
 [13.2919273   2.72021453 15.30848219 10.22434914  6.75761649  7.79885549
   1.70231654 16.31106285 -0.30338332  4.72585971 12.24874987 14.30921914
   0.69848821  3.71592512  5.72684691 11.25372073  8.77293444]
 [11.22609457  6.97299417  3.75030759 12.26424553  9.11935699  0.70598574
  14.28829517  5.76280757 -0.31105092 16.29974655 10.14720799 13.28536578
   2.7547823  15.29434077  5.79050793  7.01630173  1.72510052]
 [ 8.11554983 10.10810571  1.70048441 14.30756037 10.25168155  0.70111915
  15.29581552  2.7015427  -0.31059137 16.29914993  3.79209197 12.29183311
  10.18939498 13.29232589  4.76917386  6.80041243  5.75020111]
 [13.26129401  5.72845567 16.30748017  9.23059947  6.86060835 11.2557203
   2.70873256 15.305205   -0.29927406  3.71011608  8.94429906 14.30767562
   0.70163069  1.70374487  4.71590092 12.25900671  9.24084745]
 [15.28840654  5.83066243  8.12887505 12.28055435  2.73251612  0.70183034
  14.27798261  7.10321859 -0.31084099 16.30067549 10.21285919 12.28626318
   3.76121268 12.24011732  9.08782155  4.78249367  1.71409796]
 [13.2826814   2.71576773 16.308708   11.28198435  6.77172349  7.78662977
   1.70649739 15.30781098 -0.30635067  4.72828611 12.24657098 14.31019364
   0.70038484  3.71729362  5.738371   10.14124896  8.79194655]
 [11.26799221  3.73310547  4.73968785 10.27795919  7.86861712  0.70331412
  15.29126622  8.79561681 -0.31191458 16.30843913 13.27052132 12.29862994
   2.72990749 14.28493734  5.75890266  6.80748979  1.71107055]
 [14.26786112  3.77266409  8.03977941 11.21259415  3.75643952  0.71475571
  13.26199132  6.86328104 -0.30837563 16.31380779  9.99097219 15.28430954
   4.78919796 12.25270294  8.81914144  4.77414993  1.71576816]
 [11.25162407  3.75763337 11.20523698 11.2349606   4.76905366  0.72252938
  15.2816123   6.77363668 -0.30939601 16.31379118  8.98139541 14.28298643
   2.73448265 13.25679104  7.80934473  5.76992955  1.72148429]
 [ 9.14489883  2.72598549  4.71677141  7.9937716  10.1899925   0.71697676
  14.29491212  7.91195057 -0.31129473 16.31484683 12.196041   13.29158249
   7.83430139 15.29485814  3.72452251  7.91752604  1.71172742]
 [12.24948715  6.80018035  3.73879817  9.1448317   8.97691581  0.71966449
  12.19242059  4.76008701 -0.30132244 16.31618946  5.79285739 11.23547634
  12.19067105 15.27552698 12.17769395  2.73097716  1.72301178]
 [11.19549665  3.72387643  3.7047356  11.17657088  9.17686958  0.71726727
  14.29887591  7.76310467 -0.31056987 16.31634358 11.21136515 13.29433391
   4.75921154 15.2937538   4.72951857  6.83225932  1.71808881]
 [10.12461524  1.71813158  4.71194817 10.2129417  10.22719672  2.71833326
  14.30186323  5.73349927 -0.31254191 16.31425881 12.2093457  12.29074128
   4.74011907 15.3037076   5.74612241  9.14293969  0.70808675]
 [10.06800177 10.15108544  8.18011299 13.28434006  7.92461497  0.71066269
  14.26661957  3.72525534 -0.30586379 16.31213594  3.7785923  15.28835575
   8.94353391 12.19352129  1.72644388  4.7696719   4.75226372]
 [10.24704583  2.74010208  4.71455478 10.18605797  6.884678    0.70313425
  14.28854156 10.20272342 -0.31181864 16.31378145 13.25581855 12.29314362
   5.83573919 15.28564808  3.73279667  8.16063571  1.70366675]
 [11.24772306  3.7449012   5.72551199 10.22749328  6.83315476  0.70552062
  15.28012106 10.21423716 -0.31085702 16.31383485 12.23568966 13.29704398
   2.73858182 13.26456746  4.74494383  8.13544039  1.71360189]
 [11.18949914  4.75126381  2.70906605 11.2107786   9.10045951  0.7156492
  15.29915002  6.77497608 -0.31209672 16.3151538  11.14749818 13.29538871
   6.81286228 14.28568829  3.72699521  6.95561445  1.71575498]]
随时间推移的准确率 0.3333333333333333
---------mlp_binary------------
准确度: 0.9925373134328358
混淆矩阵:
[[59  1]
 [ 0 74]]
精确度: 0.9866666666666667
召回率: 1.0
F1分数: 0.9932885906040269
FAR: 0.0167
FRR: 0.0000
[0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]
随时间推移的准确率 0.6333333333333333
-----------mlp_multi------------
准确度: 1.0
混淆矩阵:
[[5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]]
精确度: 1.0
召回率: 1.0
F1分数: 1.0
['19' '21' '21' '21' '21' '21' '21' '21' '21' '19' '19' '12' '14' '19'
 '21' '14' '12' '21' '19' '21' '21' '21' '21' '21' '21' '21' '21' '21'
 '21' '21'] ['2' '2' '2' '2' '2' '2' '2' '2' '2' '2' '13' '13' '13' '13' '13' '13'
 '13' '13' '13' '13' '21' '21' '21' '21' '21' '21' '21' '21' '21' '21']
随时间推移的准确率 0.3333333333333333
